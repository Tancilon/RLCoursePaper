@article{DBLP:journals/corr/HasseltGS15,
  author     = {Hado van Hasselt and
                Arthur Guez and
                David Silver},
  title      = {Deep Reinforcement Learning with Double Q-learning},
  journal    = {CoRR},
  volume     = {abs/1509.06461},
  year       = {2015},
  url        = {http://arxiv.org/abs/1509.06461},
  eprinttype = {arXiv},
  eprint     = {1509.06461},
  timestamp  = {Wed, 24 Sep 2025 16:21:15 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/HasseltGS15.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/MnihKSGAWR13,
  author     = {Volodymyr Mnih and
                Koray Kavukcuoglu and
                David Silver and
                Alex Graves and
                Ioannis Antonoglou and
                Daan Wierstra and
                Martin A. Riedmiller},
  title      = {Playing Atari with Deep Reinforcement Learning},
  journal    = {CoRR},
  volume     = {abs/1312.5602},
  year       = {2013},
  url        = {http://arxiv.org/abs/1312.5602},
  eprinttype = {arXiv},
  eprint     = {1312.5602},
  timestamp  = {Wed, 24 Sep 2025 16:21:15 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/MnihKSGAWR13.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/WangFL15,
  author     = {Ziyu Wang and
                Nando de Freitas and
                Marc Lanctot},
  title      = {Dueling Network Architectures for Deep Reinforcement Learning},
  journal    = {CoRR},
  volume     = {abs/1511.06581},
  year       = {2015},
  url        = {http://arxiv.org/abs/1511.06581},
  eprinttype = {arXiv},
  eprint     = {1511.06581},
  timestamp  = {Mon, 13 Aug 2018 16:48:17 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/WangFL15.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{watkins1992qlearning,
  title     = {Q-learning},
  author    = {Watkins, Christopher J. C. H. and Dayan, Peter},
  journal   = {Machine Learning},
  volume    = {8},
  number    = {3-4},
  pages     = {279--292},
  year      = {1992},
  publisher = {Springer}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={Journal of Machine Learning Research},
  volume={17},
  number={39},
  pages={1--40},
  year={2016}
}

@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G and others},
  volume={1},
  number={1},
  year={1998},
  publisher={MIT press Cambridge}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{thrun2014issues,
  title={Issues in using function approximation for reinforcement learning},
  author={Thrun, Sebastian and Schwartz, Anton},
  booktitle={Proceedings of the 1993 connectionist models summer school},
  pages={255--263},
  year={2014},
  organization={Psychology Press}
}

@article{hasselt2010double,
  title={Double Q-learning},
  author={Hasselt, Hado},
  journal={Advances in neural information processing systems},
  volume={23},
  year={2010}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{towers2024gymnasium,
  title={Gymnasium: A standard interface for reinforcement learning environments},
  author={Towers, Mark and Kwiatkowski, Ariel and Terry, Jordan and Balis, John U and De Cola, Gianluca and Deleu, Tristan and Goul{\~a}o, Manuel and Kallinteris, Andreas and Krimmel, Markus and KG, Arjun and others},
  journal={arXiv preprint arXiv:2407.17032},
  year={2024}
}

@incollection{sewak2019deep,
  title={Deep q network (dqn), double dqn, and dueling dqn: A step towards general artificial intelligence},
  author={Sewak, Mohit},
  booktitle={Deep reinforcement learning: frontiers of artificial intelligence},
  pages={95--108},
  year={2019},
  publisher={Springer}
}

@inproceedings{hessel2018rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}

@article{byeon2023advances,
  title={Advances in value-based, policy-based, and deep learning-based reinforcement learning},
  author={Byeon, Haewon},
  journal={International Journal of Advanced Computer Science and Applications},
  volume={14},
  number={8},
  year={2023},
  publisher={Science and Information (SAI) Organization Limited}
}